{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1WWBDtT06mWKNAd3_RPqcwCvYOOAmSYv-","timestamp":1711498892552}],"gpuType":"T4","authorship_tag":"ABX9TyPs9yo6+tKq++W8RP+o7s4+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://docs.ultralytics.com/models/yolov9/#generalized-efficient-layer-aggregation-network-gelan\n","\n","https://tech.aru-zakki.com/yolov8-train-and-infer/\n","\n","https://blog.roboflow.com/train-yolov9-model/"],"metadata":{"id":"K9INA-6uboNv"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_ukZ3tpbvnu","executionInfo":{"status":"ok","timestamp":1711523463577,"user_tz":-540,"elapsed":4,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"4d7367bc-c55e-4abe-d8de-f7f81933de4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Mar 27 07:11:02 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["```\n","folder\n","â”œâ”€â”¬ test\n","â”‚  â”œâ”€â”¬  images\n","â”‚  â”‚  â”œ  ....\n","â”‚  â”‚  â””  image_A.png\n","â”‚  â””â”€â”¬  labels\n","â”‚      â”œ  ....\n","â”‚      â””  image_A.txt\n","â”œâ”€â”¬ train\n","â”‚  â”œâ”€â”¬  images\n","â”‚  â”‚  â”œ  ....\n","â”‚  â”‚  â””  image_B.png\n","â”‚  â””â”€â”¬ labels\n","â”‚      â”œ  ....\n","â”‚      â””  image_B.txt\n","â”œâ”€â”¬ valid\n","â”‚  â”œâ”€â”¬  images\n","â”‚  â”‚  â”œ  ....\n","â”‚  â”‚  â””  image_C.png\n","â”‚  â””â”€â”¬  labels\n","â”‚      â”œ  ....\n","â”‚      â””  image_C.txt\n","â””â”€â”€ data.yaml\n","```\n","\n","\n","\n","txt\n","```\n","2 0.7268229166666667 0.4476851851851852 0.008854166666666666 0.03796296296296296\n","2 0.7122395833333334 0.45925925925925926 0.009895833333333333 0.037037037037037035\n","2 0.5770833333333333 0.412962962962963 0.00625 0.03148148148148148\n","2 0.5213541666666667 0.3990740740740741 0.00625 0.027777777777777776\n","2 0.3411458333333333 0.5268518518518519 0.010416666666666666 0.044444444444444446\n","2 0.8026041666666667 0.5055555555555555 0.008333333333333333 0.044444444444444446\n","3 0.59375 0.487962962962963 0.014583333333333334 0.046296296296296294\n","2 0.43020833333333336 0.4648148148148148 0.013541666666666667 0.040740740740740744\n","2 0.6052083333333333 0.538425925925926 0.011458333333333333 0.04722222222222222\n","2 0.6721354166666667 0.5231481481481481 0.0109375 0.044444444444444446\n","2 0.8869791666666667 0.5986111111111111 0.01875 0.06018518518518518\n","2 0.42213541666666665 0.6027777777777777 0.013020833333333334 0.06111111111111111\n","2 0.296875 0.6564814814814814 0.028125 0.07407407407407407\n","2 0.40520833333333334 0.4625 0.015625 0.03981481481481482\n","2 0.9708333333333333 0.7319444444444444 0.030208333333333334 0.06944444444444445\n","2 0.9192708333333334 0.6583333333333333 0.019791666666666666 0.06481481481481481\n","1 0.09186458333333333 0.5050925925925925 0.008854166666666666 0.04537037037037037\n","2 0.47708333333333336 0.5046296296296297 0.0125 0.05\n","2 0.9546875 0.6097222222222223 0.016666666666666666 0.06018518518518518\n","2 0.6955729166666667 0.5819444444444445 0.0203125 0.05648148148148148\n","2 0.5734375 0.7699074074074074 0.021875 0.07685185185185185\n","0 0.110671875 0.52275 0.0065625 0.012194444444444444\n","3 0.45644270833333334 0.3703796296296296 0.008979166666666667 0.031055555555555555\n","2 0.7961979166666667 0.48760185185185184 0.015151041666666667 0.05038888888888889\n","```\n"],"metadata":{"id":"b-3zkrV1iNv_"}},{"cell_type":"markdown","source":["```\n","names: # ã‚¯ãƒ©ã‚¹å(ä¸Šã‹ã‚‰é †ç•ªã«0,1,2,3ã¨ãªã‚‹ã€‚0:ballã§ã‚‚è‰¯ã„)\n","- ball\n","- goalkeeper\n","- player\n","- referee\n","nc: 4 # ã‚¯ãƒ©ã‚¹æ•°\n","path:  ../dataset # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹\n","test: ../test/images # pathã«å¯¾ã™ã‚‹ç›¸å¯¾ãƒ‘ã‚¹\n","train: football-players-detection-8/train/images\n","val: football-players-detection-8/valid/images\n","```"],"metadata":{"id":"XlD9Ajtnh-Zu"}},{"cell_type":"markdown","source":["https://docs.ultralytics.com/datasets/detect/coco8/#introduction\n","\n","```\n","# Ultralytics YOLO ğŸš€, AGPL-3.0 license\n","# COCO8 dataset (first 8 images from COCO train2017) by Ultralytics\n","# Documentation: https://docs.ultralytics.com/datasets/detect/coco8/\n","# Example usage: yolo train data=coco8.yaml\n","# parent\n","# â”œâ”€â”€ ultralytics\n","# â””â”€â”€ datasets\n","#     â””â”€â”€ coco8  â† downloads here (1 MB)\n","\n","# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n","path: ../datasets/coco8 # dataset root dir\n","train: images/train # train images (relative to 'path') 4 images\n","val: images/val # val images (relative to 'path') 4 images\n","test: # test images (optional)\n","\n","# Classes\n","names:\n","  0: person\n","  1: bicycle\n","  2: car\n","  3: motorcycle\n","  4: airplane\n","  5: bus\n","  6: train\n","  7: truck\n","  8: boat\n","  9: traffic light\n","  10: fire hydrant\n","  11: stop sign\n","  12: parking meter\n","  13: bench\n","  14: bird\n","  15: cat\n","  16: dog\n","  17: horse\n","  18: sheep\n","  19: cow\n","  20: elephant\n","  21: bear\n","  22: zebra\n","  23: giraffe\n","  24: backpack\n","  25: umbrella\n","  26: handbag\n","  27: tie\n","  28: suitcase\n","  29: frisbee\n","  30: skis\n","  31: snowboard\n","  32: sports ball\n","  33: kite\n","  34: baseball bat\n","  35: baseball glove\n","  36: skateboard\n","  37: surfboard\n","  38: tennis racket\n","  39: bottle\n","  40: wine glass\n","  41: cup\n","  42: fork\n","  43: knife\n","  44: spoon\n","  45: bowl\n","  46: banana\n","  47: apple\n","  48: sandwich\n","  49: orange\n","  50: broccoli\n","  51: carrot\n","  52: hot dog\n","  53: pizza\n","  54: donut\n","  55: cake\n","  56: chair\n","  57: couch\n","  58: potted plant\n","  59: bed\n","  60: dining table\n","  61: toilet\n","  62: tv\n","  63: laptop\n","  64: mouse\n","  65: remote\n","  66: keyboard\n","  67: cell phone\n","  68: microwave\n","  69: oven\n","  70: toaster\n","  71: sink\n","  72: refrigerator\n","  73: book\n","  74: clock\n","  75: vase\n","  76: scissors\n","  77: teddy bear\n","  78: hair drier\n","  79: toothbrush\n","\n","# Download script/URL (optional)\n","download: https://ultralytics.com/assets/coco8.zip\n","```"],"metadata":{"id":"r8lv_6QIiGQT"}},{"cell_type":"code","source":["import os\n","HOME = os.getcwd()\n","print(HOME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbYoNJcWdd21","executionInfo":{"status":"ok","timestamp":1711524013016,"user_tz":-540,"elapsed":2,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"1f31b470-eb42-447e-b7db-c7d9763d14c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/SkalskiP/yolov9.git\n","%cd yolov9\n","!pip install -r requirements.txt -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"roHoM7kPdgxB","executionInfo":{"status":"ok","timestamp":1711524099116,"user_tz":-540,"elapsed":83120,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"c28c45ff-0d36-4372-89d9-4e7c084737f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov9'...\n","remote: Enumerating objects: 325, done.\u001b[K\n","remote: Counting objects: 100% (202/202), done.\u001b[K\n","remote: Compressing objects: 100% (84/84), done.\u001b[K\n","remote: Total 325 (delta 152), reused 118 (delta 118), pack-reused 123\u001b[K\n","Receiving objects: 100% (325/325), 2.26 MiB | 28.60 MiB/s, done.\n","Resolving deltas: 100% (161/161), done.\n","/content/yolov9\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n","!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n","!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n","!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"],"metadata":{"id":"c0-ZL37Id6Ji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import roboflow\n","roboflow.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmSBeqUtphi5","executionInfo":{"status":"ok","timestamp":1711524154592,"user_tz":-540,"elapsed":36565,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"2b191dc8-ddb2-4d5f-ce0b-96de3e218381"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\rvisit https://app.roboflow.com/auth-cli to get your authentication token.\n","Paste the authentication token here: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]}]},{"cell_type":"code","source":["%cd {HOME}/yolov9\n","rf = roboflow.Roboflow()\n","project = rf.workspace(\"hbk\").project(\"animal-detector-v6koq\")\n","version = project.version(1)\n","dataset = version.download(\"yolov9\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gcs4TLKoo8DO","executionInfo":{"status":"ok","timestamp":1711524165190,"user_tz":-540,"elapsed":6047,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"63f68d28-2700-402f-a47a-b88d4f1da8cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov9\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Animal-Detector-1 to yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7988/7988 [00:01<00:00, 4621.59it/s] "]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Animal-Detector-1 in yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<00:00, 6346.55it/s]\n"]}]},{"cell_type":"code","source":["!ls -la {HOME}/weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJqUhWKceDSt","executionInfo":{"status":"ok","timestamp":1711524177893,"user_tz":-540,"elapsed":868,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"d4645255-bd96-4ef7-af60-07aae3cb43a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 402440\n","drwxr-xr-x 2 root root      4096 Mar 27 07:21 .\n","drwxr-xr-x 1 root root      4096 Mar 27 07:21 ..\n","-rw-r--r-- 1 root root  51508261 Feb 18 12:36 gelan-c.pt\n","-rw-r--r-- 1 root root 117203713 Feb 18 12:36 gelan-e.pt\n","-rw-r--r-- 1 root root 103153312 Feb 18 12:36 yolov9-c.pt\n","-rw-r--r-- 1 root root 140217688 Feb 18 12:36 yolov9-e.pt\n"]}]},{"cell_type":"code","source":["SOURCE_IMAGE_PATH = f\"{HOME}/yolov9/Animal-Detector-1/valid/images/boar005_jpg.rf.5243ea3d65f64be99548446fa7be54b6.jpg\""],"metadata":{"id":"hstqmW3EeJ1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python detect.py --weights {HOME}/weights/gelan-c.pt --conf 0.1 --source {SOURCE_IMAGE_PATH} --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJzqNxg3eZn5","executionInfo":{"status":"ok","timestamp":1711524228401,"user_tz":-540,"elapsed":9877,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"8243dbde-c8bf-47aa-825e-3b6a9ea4a0c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/weights/gelan-c.pt'], source=/content/yolov9/Animal-Detector-1/valid/images/boar005_jpg.rf.5243ea3d65f64be99548446fa7be54b6.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 ğŸš€ 1e33dbb Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 467 layers, 25472640 parameters, 0 gradients, 102.8 GFLOPs\n","image 1/1 /content/yolov9/Animal-Detector-1/valid/images/boar005_jpg.rf.5243ea3d65f64be99548446fa7be54b6.jpg: 640x640 1 dog, 1 bear, 51.9ms\n","Speed: 0.6ms pre-process, 51.9ms inference, 702.6ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"]}]},{"cell_type":"code","source":["dataset.location"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"cCtV_hxyrdLx","executionInfo":{"status":"ok","timestamp":1711524375294,"user_tz":-540,"elapsed":603,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"775e61de-0916-4ce5-b2fb-3f6bebaf4161"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/yolov9/Animal-Detector-1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["%cd {HOME}/yolov9\n","\n","!python train.py \\\n","--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 \\\n","--data /content/yolov9/Animal-Detector-1/data.yaml \\\n","--weights /content/weights/gelan-c.pt \\\n","--cfg /content/yolov9/models/detect/gelan-c.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gb-veCcagdQk","executionInfo":{"status":"ok","timestamp":1711524795065,"user_tz":-540,"elapsed":16909,"user":{"displayName":"HIBIKI KIMURA","userId":"07360203312747025865"}},"outputId":"d6b5f42d-b16a-46ac-b4d9-c51ea52baa7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov9\n","2024-03-27 07:33:01.758897: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-27 07:33:01.758955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-27 07:33:01.760312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-27 07:33:02.851990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/weights/gelan-c.pt, cfg=/content/yolov9/models/detect/gelan-c.yaml, data=/content/yolov9/Animal-Detector-1/data.yaml, hyp=data/hyps/hyp.scratch-high.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLOv5 ğŸš€ 1e33dbb Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ğŸš€ in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ğŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n","  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n","  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n","  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n","  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n"," 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n"," 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n"," 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n"," 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n"," 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n"," 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n"," 22      [15, 18, 21]  1   5491411  models.yolo.DDetect                     [1, [256, 512, 512]]          \n","gelan-c summary: 621 layers, 25437843 parameters, 25437827 gradients, 103.2 GFLOPs\n","\n","Transferred 931/937 items from /content/weights/gelan-c.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov9/Animal-Detector-1/train/labels... 99 images, 0 backgrounds, 0 corrupt: 100% 99/99 [00:00<00:00, 604.45it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov9/Animal-Detector-1/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov9/Animal-Detector-1/valid/labels... 10 images, 0 backgrounds, 0 corrupt: 100% 10/10 [00:00<00:00, 153.49it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov9/Animal-Detector-1/valid/labels.cache\n","Plotting labels to runs/train/exp3/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp3\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","  0% 0/7 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/content/yolov9/train_dual.py\", line 644, in <module>\n","    main(opt)\n","  File \"/content/yolov9/train_dual.py\", line 538, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"/content/yolov9/train_dual.py\", line 288, in train\n","    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1181, in __iter__\n","    for obj in iterable:\n","  File \"/content/yolov9/utils/dataloaders.py\", line 170, in __iter__\n","    yield next(self.iterator)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n","    return self._process_data(data)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n","    data.reraise()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 722, in reraise\n","    raise exception\n","IndexError: Caught IndexError in DataLoader worker process 0.\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n","    data = fetcher.fetch(index)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/content/yolov9/utils/dataloaders.py\", line 656, in __getitem__\n","    img, labels = self.load_mosaic(index)\n","  File \"/content/yolov9/utils/dataloaders.py\", line 791, in load_mosaic\n","    img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=self.hyp['copy_paste'])\n","  File \"/content/yolov9/utils/augmentations.py\", line 248, in copy_paste\n","    l, box, s = labels[j], boxes[j], segments[j]\n","IndexError: list index out of range\n","\n"]}]}]}